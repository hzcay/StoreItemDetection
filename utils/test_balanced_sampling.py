"""
Script test weighted sampling vÃ  class weights cho situ dataset
Kiá»ƒm tra xem cÃ³ cÃ¢n báº±ng Ä‘Æ°á»£c cÃ¡c class khÃ´ng
"""
import sys
from pathlib import Path

import torch
from torch.utils.data import DataLoader
from collections import Counter

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from models.situ_finetune.finetune_situ import (
    SituDataset, 
    create_data_loaders,
    get_class_weights,
    create_weighted_sampler
)


def analyze_sampling_distribution(data_loader, num_samples: int = 1000):
    """
    PhÃ¢n tÃ­ch phÃ¢n bá»‘ class khi sampling
    
    Args:
        data_loader: DataLoader
        num_samples: Sá»‘ samples Ä‘á»ƒ phÃ¢n tÃ­ch
    
    Returns:
        Dict vá»›i phÃ¢n bá»‘ class
    """
    class_counts = Counter()
    total_samples = 0
    
    for batch_idx, (images, labels) in enumerate(data_loader):
        for label in labels:
            class_counts[label.item()] += 1
            total_samples += 1
            
            if total_samples >= num_samples:
                break
        
        if total_samples >= num_samples:
            break
    
    return class_counts, total_samples


def compare_distributions(original_counts, sampled_counts):
    """
    So sÃ¡nh phÃ¢n bá»‘ gá»‘c vs sau khi weighted sampling
    
    Args:
        original_counts: Counter tá»« dataset gá»‘c
        sampled_counts: Counter tá»« sampled data
    """
    print(f"\n{'='*70}")
    print("ðŸ“Š SO SÃNH PHÃ‚N Bá» CLASS")
    print(f"{'='*70}")
    
    # TÃ­nh statistics
    original_values = list(original_counts.values())
    sampled_values = list(sampled_counts.values())
    
    # Láº¥y cÃ¡c class chung
    all_classes = set(original_counts.keys()) | set(sampled_counts.keys())
    
    print(f"\nðŸ“ˆ Thá»‘ng kÃª phÃ¢n bá»‘ gá»‘c:")
    print(f"   Min: {min(original_values)}")
    print(f"   Max: {max(original_values)}")
    print(f"   Mean: {sum(original_values) / len(original_values):.2f}")
    print(f"   Std: {(sum((x - sum(original_values)/len(original_values))**2 for x in original_values) / len(original_values))**0.5:.2f}")
    
    print(f"\nðŸ“ˆ Thá»‘ng kÃª phÃ¢n bá»‘ sau weighted sampling:")
    print(f"   Min: {min(sampled_values) if sampled_values else 0}")
    print(f"   Max: {max(sampled_values) if sampled_values else 0}")
    if sampled_values:
        mean_sampled = sum(sampled_values) / len(sampled_values)
        print(f"   Mean: {mean_sampled:.2f}")
        std_sampled = (sum((x - mean_sampled)**2 for x in sampled_values) / len(sampled_values))**0.5
        print(f"   Std: {std_sampled:.2f}")
    
    # So sÃ¡nh ratio
    original_ratio = max(original_values) / min(original_values) if min(original_values) > 0 else float('inf')
    if sampled_values and min(sampled_values) > 0:
        sampled_ratio = max(sampled_values) / min(sampled_values)
        improvement = ((original_ratio - sampled_ratio) / original_ratio) * 100
        print(f"\nðŸ“Š Imbalance Ratio:")
        print(f"   Gá»‘c: {original_ratio:.2f}x")
        print(f"   Sau weighted sampling: {sampled_ratio:.2f}x")
        print(f"   Cáº£i thiá»‡n: {improvement:.1f}%")
    
    # Hiá»ƒn thá»‹ top 10 classes Ã­t nháº¥t vÃ  nhiá»u nháº¥t
    print(f"\n   Top 10 classes Ã­t áº£nh nháº¥t (gá»‘c):")
    sorted_original = sorted(original_counts.items(), key=lambda x: x[1])
    for class_id, count in sorted_original[:10]:
        sampled_count = sampled_counts.get(class_id, 0)
        print(f"      Class {class_id:3d}: Gá»‘c={count:4d}, Sampled={sampled_count:4d}")
    
    print(f"\n   Top 10 classes nhiá»u áº£nh nháº¥t (gá»‘c):")
    sorted_original_desc = sorted(original_counts.items(), key=lambda x: x[1], reverse=True)
    for class_id, count in sorted_original_desc[:10]:
        sampled_count = sampled_counts.get(class_id, 0)
        print(f"      Class {class_id:3d}: Gá»‘c={count:4d}, Sampled={sampled_count:4d}")


def test_balanced_sampling(data_dir: str):
    """
    Test weighted sampling vÃ  class weights
    
    Args:
        data_dir: ÄÆ°á»ng dáº«n Ä‘áº¿n data situ
    """
    print("="*70)
    print("ðŸ§ª TEST BALANCED SAMPLING - Kiá»ƒm tra cÃ¢n báº±ng class")
    print("="*70)
    
    # Táº¡o dataset
    print("\nðŸ“¦ Loading dataset...")
    dataset = SituDataset(data_dir, transform=None)
    
    # Äáº¿m phÃ¢n bá»‘ gá»‘c
    original_labels = [label for _, label in dataset.samples]
    original_counts = Counter(original_labels)
    
    print(f"\nðŸ“Š PhÃ¢n bá»‘ gá»‘c:")
    print(f"   Tá»•ng sá»‘ áº£nh: {len(dataset.samples)}")
    print(f"   Sá»‘ classes: {len(original_counts)}")
    
    image_counts = list(original_counts.values())
    print(f"   Min: {min(image_counts)} áº£nh/class")
    print(f"   Max: {max(image_counts)} áº£nh/class")
    print(f"   Mean: {sum(image_counts) / len(image_counts):.2f} áº£nh/class")
    print(f"   Imbalance Ratio: {max(image_counts) / min(image_counts):.2f}x")
    
    # Test weighted sampling
    print(f"\nðŸ”„ Testing Weighted Sampling...")
    train_loader_with_weight, _, _, _ = create_data_loaders(
        data_dir, 
        batch_size=32, 
        use_weighted_sampling=True
    )
    
    # PhÃ¢n tÃ­ch phÃ¢n bá»‘ sau weighted sampling
    sampled_counts, num_samples = analyze_sampling_distribution(train_loader_with_weight, num_samples=5000)
    
    print(f"   ÄÃ£ sample {num_samples} áº£nh")
    print(f"   Sá»‘ classes xuáº¥t hiá»‡n: {len(sampled_counts)}")
    
    # So sÃ¡nh
    compare_distributions(original_counts, sampled_counts)
    
    # Test class weights
    print(f"\n{'='*70}")
    print("âš–ï¸  TEST CLASS WEIGHTS")
    print(f"{'='*70}")
    
    class_weights = get_class_weights(dataset, device='cpu')
    
    print(f"\nðŸ“Š Class Weights:")
    print(f"   Min weight: {class_weights.min():.2f}")
    print(f"   Max weight: {class_weights.max():.2f}")
    print(f"   Mean weight: {class_weights.mean():.2f}")
    
    # Top 10 classes cÃ³ weight cao nháº¥t (Ã­t áº£nh)
    sorted_by_weight = sorted(zip(range(len(class_weights)), class_weights.tolist()), 
                             key=lambda x: x[1], reverse=True)
    
    print(f"\n   Top 10 classes cÃ³ weight cao nháº¥t (Ã­t áº£nh):")
    for class_id, weight in sorted_by_weight[:10]:
        original_count = original_counts.get(class_id, 0)
        print(f"      Class {class_id:3d}: Weight={weight:.2f}, Sá»‘ áº£nh gá»‘c={original_count}")
    
    print(f"\n   Top 10 classes cÃ³ weight tháº¥p nháº¥t (nhiá»u áº£nh):")
    for class_id, weight in sorted_by_weight[-10:]:
        original_count = original_counts.get(class_id, 0)
        print(f"      Class {class_id:3d}: Weight={weight:.2f}, Sá»‘ áº£nh gá»‘c={original_count}")
    
    print(f"\n{'='*70}")
    print("âœ… HoÃ n thÃ nh test!")
    print(f"{'='*70}")
    print("\nðŸ’¡ Káº¿t luáº­n:")
    if len(sampled_counts) > 0:
        sampled_ratio = max(sampled_counts.values()) / min(sampled_counts.values())
        original_ratio = max(original_counts.values()) / min(original_counts.values())
        if sampled_ratio < original_ratio * 0.5:
            print("   âœ… Weighted sampling giÃºp cÃ¢n báº±ng tá»‘t (ratio giáº£m >50%)")
        elif sampled_ratio < original_ratio * 0.7:
            print("   âš ï¸  Weighted sampling giÃºp cÃ¢n báº±ng vá»«a pháº£i (ratio giáº£m 30-50%)")
        else:
            print("   âš ï¸  Weighted sampling chÆ°a Ä‘á»§, cÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh")
    
    print("   âœ… Class weights Ä‘Ã£ Ä‘Æ°á»£c tÃ­nh toÃ¡n Ä‘Ãºng")
    print("\nðŸ“ BÆ°á»›c tiáº¿p theo:")
    print("   - Náº¿u káº¿t quáº£ tá»‘t: CÃ³ thá»ƒ báº¯t Ä‘áº§u training vá»›i --use-weighted-sampling --use-class-weights")
    print("   - Náº¿u chÆ°a tá»‘t: CÃ³ thá»ƒ cáº§n augmentation cho class Ã­t áº£nh\n")


def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Test weighted sampling vÃ  class weights cho situ dataset'
    )
    parser.add_argument(
        '--data-dir',
        type=str,
        default='data/raw/inSitu/inSitu',
        help='ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c in-situ data'
    )
    
    args = parser.parse_args()
    
    test_balanced_sampling(args.data_dir)


if __name__ == '__main__':
    main()

