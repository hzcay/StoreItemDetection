"""
Script test l√†m n√©t ·∫£nh tr√™n 1 ·∫£nh situ ƒë·ªÉ ki·ªÉm tra thu·∫≠t to√°n
Hi·ªÉn th·ªã k·∫øt qu·∫£ so s√°nh tr∆∞·ªõc/sau
"""
import sys
from pathlib import Path
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import numpy as np
import matplotlib.pyplot as plt


def enhance_image_cv2(image_path: Path, strength: str = 'balanced') -> np.ndarray:
    """
    L√†m n√©t v√† c·∫£i thi·ªán ·∫£nh b·∫±ng OpenCV (phi√™n b·∫£n c√¢n b·∫±ng - gi·ªØ chi ti·∫øt)
    
    Args:
        image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
        strength: 'light', 'balanced', 'medium', 'strong'
    
    Returns:
        numpy array c·ªßa ·∫£nh ƒë√£ x·ª≠ l√Ω (RGB)
    """
    # ƒê·ªçc ·∫£nh
    img = cv2.imread(str(image_path))
    if img is None:
        raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
    
    # Chuy·ªÉn sang RGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # C·∫•u h√¨nh theo strength - c√¢n b·∫±ng gi·ªØa l√†m n√©t v√† gi·ªØ chi ti·∫øt
    if strength == 'light':
        denoise_h = 3
        denoise_hcolor = 3
        sharp_weight1, sharp_weight2 = 1.2, -0.2
        clahe_limit = 1.3
        unsharp_radius = 1.0
        use_bilateral = True
    elif strength == 'balanced':  # M·∫∑c ƒë·ªãnh - c√¢n b·∫±ng t·ªët nh·∫•t
        denoise_h = 5
        denoise_hcolor = 5
        sharp_weight1, sharp_weight2 = 1.4, -0.4
        clahe_limit = 1.8
        unsharp_radius = 1.5
        use_bilateral = True
    elif strength == 'medium':
        denoise_h = 8
        denoise_hcolor = 8
        sharp_weight1, sharp_weight2 = 1.6, -0.5
        clahe_limit = 2.2
        unsharp_radius = 2.0
        use_bilateral = False
    else:  # strong
        denoise_h = 10
        denoise_hcolor = 10
        sharp_weight1, sharp_weight2 = 1.8, -0.6
        clahe_limit = 2.5
        unsharp_radius = 2.0
        use_bilateral = False
    
    # Gi·∫£m nhi·ªÖu NH·∫∏ ƒë·ªÉ gi·ªØ chi ti·∫øt (ho·∫∑c d√πng bilateral filter ƒë·ªÉ gi·ªØ edge)
    if use_bilateral:
        # Bilateral filter gi·ªØ edge t·ªët h∆°n
        img_denoised = cv2.bilateralFilter(img_rgb, 5, 50, 50)
    else:
        # Non-local means - nh·∫π h∆°n
        img_denoised = cv2.fastNlMeansDenoisingColored(img_rgb, None, denoise_h, denoise_hcolor, 7, 21)
    
    # L√†m n√©t b·∫±ng Unsharp Mask (v·ª´a ph·∫£i ƒë·ªÉ kh√¥ng m·∫•t chi ti·∫øt)
    gaussian = cv2.GaussianBlur(img_denoised, (0, 0), unsharp_radius)
    img_sharpened = cv2.addWeighted(img_denoised, sharp_weight1, gaussian, sharp_weight2, 0)
    
    # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n (CLAHE) - v·ª´a ph·∫£i ƒë·ªÉ kh√¥ng l√†m m·∫•t chi ti·∫øt
    lab = cv2.cvtColor(img_sharpened, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=clahe_limit, tileGridSize=(8, 8))
    l = clahe.apply(l)
    img_enhanced = cv2.merge([l, a, b])
    img_enhanced = cv2.cvtColor(img_enhanced, cv2.COLOR_LAB2RGB)
    
    # L√†m n√©t nh·∫π l·∫ßn cu·ªëi (r·∫•t nh·∫π ƒë·ªÉ kh√¥ng l√†m m·∫•t chi ti·∫øt)
    gaussian_final = cv2.GaussianBlur(img_enhanced, (0, 0), 0.8)
    img_final = cv2.addWeighted(img_enhanced, 1.1, gaussian_final, -0.1, 0)
    
    # ƒê·∫£m b·∫£o gi√° tr·ªã trong range [0, 255]
    img_final = np.clip(img_final, 0, 255).astype(np.uint8)
    
    return img_final


def enhance_image_pil(image_path: Path) -> Image.Image:
    """
    L√†m n√©t v√† c·∫£i thi·ªán ·∫£nh b·∫±ng PIL
    
    Returns:
        PIL Image ƒë√£ x·ª≠ l√Ω
    """
    image = Image.open(image_path).convert('RGB')
    
    # L√†m n√©t
    image = image.filter(ImageFilter.UnsharpMask(radius=1, percent=150, threshold=3))
    enhancer = ImageEnhance.Sharpness(image)
    image = enhancer.enhance(1.5)
    
    # TƒÉng t∆∞∆°ng ph·∫£n
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(1.1)
    
    return image


def compare_images(original_path: Path, method: str = 'cv2', strength: str = 'balanced', save_output: bool = True):
    """
    So s√°nh ·∫£nh g·ªëc v√† ·∫£nh ƒë√£ x·ª≠ l√Ω
    
    Args:
        original_path: ƒê∆∞·ªùng d·∫´n ·∫£nh g·ªëc
        method: 'cv2' ho·∫∑c 'pil'
        strength: 'light', 'balanced', 'medium', 'strong'
        save_output: L∆∞u ·∫£nh output kh√¥ng
    """
    print(f"\n{'='*70}")
    print(f"üß™ TEST ENHANCE SITU IMAGE")
    print(f"{'='*70}")
    print(f"·∫¢nh g·ªëc: {original_path}")
    print(f"Method: {method.upper()}")
    print(f"Strength: {strength.upper()}\n")
    
    # ƒê·ªçc ·∫£nh g·ªëc
    try:
        original_img = Image.open(original_path).convert('RGB')
        original_array = np.array(original_img)
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc ·∫£nh g·ªëc: {e}")
        return
    
    # X·ª≠ l√Ω ·∫£nh
    print("üñºÔ∏è  ƒêang x·ª≠ l√Ω ·∫£nh...")
    try:
        if method == 'cv2':
            enhanced_array = enhance_image_cv2(original_path, strength=strength)
            enhanced_img = Image.fromarray(enhanced_array)
        else:
            enhanced_img = enhance_image_pil(original_path)
            enhanced_array = np.array(enhanced_img)
    except Exception as e:
        print(f"‚ùå L·ªói x·ª≠ l√Ω ·∫£nh: {e}")
        return
    
    print("‚úÖ X·ª≠ l√Ω xong!\n")
    
    # L∆∞u ·∫£nh output n·∫øu c·∫ßn
    if save_output:
        output_path = original_path.parent / f"{original_path.stem}_enhanced{original_path.suffix}"
        if method == 'cv2':
            cv2.imwrite(str(output_path), cv2.cvtColor(enhanced_array, cv2.COLOR_RGB2BGR), 
                       [cv2.IMWRITE_JPEG_QUALITY, 95])
        else:
            enhanced_img.save(output_path, quality=95)
        print(f"üíæ ƒê√£ l∆∞u ·∫£nh output: {output_path}\n")
    
    # Hi·ªÉn th·ªã so s√°nh
    print("üìä So s√°nh:")
    print(f"   K√≠ch th∆∞·ªõc g·ªëc: {original_img.size}")
    print(f"   K√≠ch th∆∞·ªõc sau: {enhanced_img.size}")
    
    # T√≠nh to√°n m·ªôt s·ªë metrics
    original_gray = cv2.cvtColor(original_array, cv2.COLOR_RGB2GRAY) if method == 'cv2' else np.array(original_img.convert('L'))
    enhanced_gray = cv2.cvtColor(enhanced_array, cv2.COLOR_RGB2GRAY) if method == 'cv2' else np.array(enhanced_img.convert('L'))
    
    # Laplacian variance (ƒëo ƒë·ªô n√©t)
    laplacian_original = cv2.Laplacian(original_gray, cv2.CV_64F).var()
    laplacian_enhanced = cv2.Laplacian(enhanced_gray, cv2.CV_64F).var()
    
    print(f"   ƒê·ªô n√©t g·ªëc (Laplacian variance): {laplacian_original:.2f}")
    print(f"   ƒê·ªô n√©t sau: {laplacian_enhanced:.2f}")
    print(f"   C·∫£i thi·ªán: {((laplacian_enhanced / laplacian_original - 1) * 100):.1f}%")
    
    # Hi·ªÉn th·ªã ·∫£nh (n·∫øu c√≥ matplotlib)
    try:
        fig, axes = plt.subplots(1, 2, figsize=(15, 7))
        
        axes[0].imshow(original_array)
        axes[0].set_title('·∫¢nh G·ªëc (Situ)', fontsize=14, fontweight='bold')
        axes[0].axis('off')
        
        axes[1].imshow(enhanced_array)
        axes[1].set_title('·∫¢nh ƒê√£ X·ª≠ L√Ω', fontsize=14, fontweight='bold')
        axes[1].axis('off')
        
        plt.tight_layout()
        
        # L∆∞u comparison image
        comparison_path = original_path.parent / f"{original_path.stem}_comparison.png"
        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
        print(f"üíæ ƒê√£ l∆∞u ·∫£nh so s√°nh: {comparison_path}")
        
        plt.show()
        print("\n‚úÖ ƒê√£ hi·ªÉn th·ªã ·∫£nh so s√°nh!")
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Kh√¥ng th·ªÉ hi·ªÉn th·ªã ·∫£nh (c√≥ th·ªÉ thi·∫øu matplotlib ho·∫∑c display): {e}")
        print("   Nh∆∞ng ·∫£nh ƒë√£ ƒë∆∞·ª£c l∆∞u, b·∫°n c√≥ th·ªÉ xem b·∫±ng image viewer")
    
    print(f"\n{'='*70}")
    print("‚úÖ Ho√†n th√†nh test!")
    print(f"{'='*70}\n")


def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Test l√†m n√©t ·∫£nh tr√™n 1 ·∫£nh situ ƒë·ªÉ ki·ªÉm tra thu·∫≠t to√°n'
    )
    parser.add_argument(
        'image_path',
        type=str,
        help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh situ c·∫ßn test (v√≠ d·ª•: data/raw/inSitu/inSitu/1/video/video1.png)'
    )
    parser.add_argument(
        '--method',
        type=str,
        choices=['cv2', 'pil'],
        default='cv2',
        help='Method x·ª≠ l√Ω: cv2 (ch·∫•t l∆∞·ª£ng t·ªët) ho·∫∑c pil (nhanh)'
    )
    parser.add_argument(
        '--strength',
        type=str,
        choices=['light', 'balanced', 'medium', 'strong'],
        default='balanced',
        help='ƒê·ªô m·∫°nh x·ª≠ l√Ω: light, balanced (gi·ªØ chi ti·∫øt - khuy·∫øn ngh·ªã), medium, strong (m·∫∑c ƒë·ªãnh: balanced)'
    )
    parser.add_argument(
        '--no-save',
        action='store_true',
        help='Kh√¥ng l∆∞u ·∫£nh output'
    )
    
    args = parser.parse_args()
    
    image_path = Path(args.image_path)
    
    if not image_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {image_path}")
        print("\nüí° V√≠ d·ª• s·ª≠ d·ª•ng:")
        print("   python utils/test_enhance_situ_image.py data/raw/inSitu/inSitu/1/video/video1.png")
        print("   python utils/test_enhance_situ_image.py data/raw/inSitu/inSitu/1/video/video1.png --method pil")
        print("   python utils/test_enhance_situ_image.py data/raw/inSitu/inSitu/1/video/video1.png --strength strong")
        return
    
    compare_images(
        original_path=image_path,
        method=args.method,
        strength=args.strength,
        save_output=not args.no_save
    )


if __name__ == '__main__':
    main()

